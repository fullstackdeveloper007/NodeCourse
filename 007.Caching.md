# Caching in Node.js**

Caching is all about storing data temporarily so that future requests can be served faster without recomputing or refetching from slow sources (like a database, API, or file system).

### **1. Why caching matters**

* **Performance:** Reduces response time.
* **Scalability:** Reduces load on database or external APIs.
* **Cost-effective:** Fewer DB/API calls = lower server cost.

### **2. Types of Caching**

#### **a) In-memory cache**

Stored in the server’s memory.

* **Pros:** Fast, simple.
* **Cons:** Limited by memory, not shared across multiple instances.
* **Libraries:** `node-cache`, `lru-cache`.

**Example using `node-cache`:**

```javascript
const NodeCache = require("node-cache");
const myCache = new NodeCache({ stdTTL: 100, checkperiod: 120 });

function getUser(id) {
  const cachedUser = myCache.get(id);
  if (cachedUser) {
    return Promise.resolve(cachedUser);
  }
  return fetchUserFromDB(id).then(user => {
    myCache.set(id, user);
    return user;
  });
}
```

---

#### **b) Distributed cache**

Stored outside the server, shared across multiple instances.

* **Common tools:** Redis, Memcached.
* **Pros:** Scales with multiple servers, persistent (optional).
* **Cons:** Requires network call.

**Example using Redis:**

```javascript
const redis = require("redis");
const client = redis.createClient();
await client.connect();

async function getUser(id) {
  const cachedUser = await client.get(`user:${id}`);
  if (cachedUser) return JSON.parse(cachedUser);

  const user = await fetchUserFromDB(id);
  await client.setEx(`user:${id}`, 3600, JSON.stringify(user)); // expires in 1 hour
  return user;
}
```

---

### **3. Caching strategies**

1. **Cache-aside (Lazy loading)**
   Load data into cache only when requested.

   * Pros: Simple, cache only needed data.
   * Cons: First request is slow (cache miss).

2. **Write-through / write-back**

   * Write-through: Write to cache and DB simultaneously.
   * Write-back: Write to cache first, DB updated asynchronously.
   * Pros: Consistent data.
   * Cons: Complexity.

3. **Time-to-Live (TTL)**

   * Automatically expire cached data after a certain time.

4. **Cache invalidation**

   * Delete/update cache when data changes in DB.

---

### **4. Node.js Specific Notes**

* Node.js is single-threaded. So in-memory caches are fast for small data but don’t scale horizontally. For multi-instance deployments, Redis is better.
* Avoid caching huge objects in memory; memory leaks can crash your server.
* Use LRU (Least Recently Used) caching for limited memory caches (`lru-cache` library).

--- 
